# 从0开始手搓基于C语言的数据结构算法库

## 0：开始之前

### 0.0 什么是数据结构与算法

​	在开始我们的手搓之前，我们往往需要理解，何为算法，何为数据结构。

​	一般的教科书中，或者是任何诸如Youtube，Bilibili等学习网站，会一本正经的告诉你如下的定义。

> :question: 算法：算法是解决特定问题的一系列明确步骤或指令。它描述了从输入到输出的计算过程，确保在有限步骤:question: 内得到结果。
>
> :question: 数据结构：数据结构是组织和存储数据的方式，以便高效访问和修改。它涉及数据元素之间的关系及对其的操作。

​	很好，看完也不知道在说啥。笔者来说一嘴：

> :exclamation: 算法就是说明我们如何按照步骤，使用给定的信息，解决给定的问题，追求效率最快的，成本最低的产出我们期望的结果
>
> :exclamation:数据结构则是约束了我们如何存储我们的数据？是零碎的存？有下标的存？还是存在配对的存？（关于数据在计算机中的存储方式不是我们教程的重点，你只需要想象一个巨大无比的餐厅里如何安排你的游客在指定的地点里坐下，而不是让他们鸡飞狗跳到处乱串）​

### 0.1 如何衡量我们的数据结构和算法

​	好吧，我们必须承认，我们需要一个排除主观因素的评价一个数据结构算法体系好坏的一个指标。我们说，一个算法好不好，一个数据结构好不好，在于他能不能高效的解决我们目标的需求领域的难题。解决这个问题，就需要我们了解每一个数据结构，每一种算法的优缺点，他们的实现，他们可能潜在的问题和他们能够解决的难点在什么地方。当然，这考验我的能力，也是我为什么主张学习数据结构和算法的时候需要进行手搓，而不是葫芦吞枣走马观花的学习的一个重要的原因！

​	所以，回到我们的问题，如果衡量我们的数据结构和算法？我们仔细想象，对于一个小的数据量，我精心优化的一个超级牛逼的算法，和一个疯狂的暴力遍历以至于行外人都感到愚蠢的算法，处理的执行时间，和消耗的硬件资源（比如说我们的电脑内存，硬存等等），看起来似乎不是差距很大，一台电脑照样可以跑。

​	但是，当数据量一大起来，前者这种精心的低开销的设计，可以保证几乎时间不变和硬件资源几乎没有特别大膨胀的情况下，照样跑出正确的结果；与之鲜明对比的后者则是让你烦躁的发现程序卡死，电脑罢工，你也只好尴尬的关掉你的电脑，重新打开你的VSCode或者是任何你喜欢的编辑器，然后苦苦构思你的算法到底哪里出现了问题。这样看，我们评价一个算法的优劣，需要一个明确的场景——至少一个！那就是我们的数据量的大小。

> :heavy_check_mark: ：一个好的算法，是**一个对于给定问题和场景下**，对**输入的数据量的大小是脱敏**的，给定多大的数据量，他的执行时间和处理消耗的资源都是低增长的，完全可以拿下几乎可以说是任意的数据量大小的场景
>
> :negative_squared_cross_mark: ​：当然，一个不优秀的算法就是与之相反，我们几乎只敢对我们的上司，我们的同事，我们的共事者唯唯诺诺的乞求不要把自己写的代码放到大数据量的生产环境，因为显然这样的算法完全没法解决给定的问题——一般是过大的数据量导致处理的呆板导致程序运行时间几乎不可接受！

​	所以，我们引入了算法复杂度这个东西，他衡量了一个算法跟一个数据规模大小为N（不妨理解为N个数据？它可以是几个，十几个，几十个，成白上千，几千万几个亿的数据）的场景下，它所消耗的时间资源大小和硬件（常见的是空间）资源大小的规模是如何的（也就是，我们的算法对于一个规模的数据，处理执行的时间和消耗的空间大小多大呢？）。一般的，**我们使用一个叫做大O计数法的东西来衡量我们算法的复杂度**，他是一个大概，而非精准的描述。

​	比如说，我们会将一个`O(N)`的算法复杂度称作**一个复杂度线性增长的算法**，因为它的消耗的时间和资源是跟数据规模成近似正相关的算法。比如说，一个经典的遍历查找算法。

```c
int find_target_linear(const int value, const int* array, const int array_size)
{
	for(int i = 0; i < array_size; i++)
    {
        if(value == array[i])
            return i;	// we find the value, so returns the index for the outlier usage
    }
    return -1;	// we find nothing, how saddy!
}
```

​	十个数据，我们最差会找十次才找到，一百个数据，我们最差会找一百次才找到。。。那更多呢，嗯，没办法的事情。当然，查找是我们这个教程中一个非常，非常大的话题，所以不着急。当你认为线性遍历的查找实在是显得呆板的时候，我们后面介绍的查找算法总是会让你感到惊艳的。

​	常见的算法复杂度如下所示：



| :clock1:复杂度 | :name_badge: 名称 | :pen:描述                                                    | :grey_exclamation:示例算法   |
| -------------- | ----------------- | ------------------------------------------------------------ | ---------------------------- |
| O(1)           | 常数时间复杂度    | 算法的执行时间不随输入规模变化，始终为常数。                 | 数组索引访问、哈希表查找     |
| O(log n)       | 对数时间复杂度    | 算法的执行时间随输入规模呈对数增长，效率高。                 | 二分查找、平衡二叉搜索树操作 |
| O(n)           | 线性时间复杂度    | 算法的执行时间与输入规模成正比。                             | 线性搜索、遍历数组           |
| O(n log n)     | 线性对数复杂度    | 算法的执行时间随输入规模呈线性对数增长，常见于高效排序算法。 | 快速排序、归并排序、堆排序   |
| O(n²)          | 平方时间复杂度    | 算法的执行时间与输入规模的平方成正比，效率较低。             | 冒泡排序、选择排序、插入排序 |
| O(n³)          | 立方时间复杂度    | 算法的执行时间与输入规模的立方成正比，效率更低。             | 简单的矩阵乘法               |
| O(2ⁿ)          | 指数时间复杂度    | 算法的执行时间随输入规模呈指数增长，通常不可接受。           | 穷举搜索、某些递归问题       |
| O(n!)          | 阶乘时间复杂度    | 算法的执行时间随输入规模的阶乘增长，效率极低。               | 旅行商问题的穷举解法         |
| O(n^k)         | 多项式复杂度      | 算法的执行时间与输入规模的某个幂次成正比，k为常数。          | 某些动态规划问题             |
| O(m + n)       | 线性相加复杂度    | 算法的执行时间与两个输入规模的和成正比。                     | 图的广度优先搜索（BFS）      |
| O(m * n)       | 线性相乘复杂度    | 算法的执行时间与两个输入规模的乘积成正比。                   | 嵌套循环遍历二维数组         |

​	好多新的名词，不必着急，我们会慢慢的讨论的，请不必着急！我们需要做的，就是经可能将自己的算法逼近到`O(1)`，或者说，逼近到一个理论的极限！所以，这场手搓一定是一个艰难的过程！